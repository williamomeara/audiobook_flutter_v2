# TTS Implementation - Executive Summary for AI Agent

**Send this to your AI agent to kickstart Phase 1.**

---

## What You're Building

An audiobook app with **on-device, high-quality TTS** using:
- **Kokoro** (flexible, 1-2 sec/sentence on INT8)
- **Piper** (production TTS, lower latency)
- **Supertonic** (advanced voice cloning)

All synthesize to **WAV files on disk** (cache-friendly) and play via **just_audio**.

---

## Architecture (15-Second Version)

```
Dart App (tts_engines package)
    ↓ [MethodChannel via Pigeon]
Android Native (Kotlin)
    ├─ KokoroTtsService (ONNX Runtime)
    ├─ PiperTtsService (ONNX Runtime + phonemizer)
    └─ SupertonicTtsService (ONNX Runtime + embeddings)
```

**Key insight:** Dart calls native via MethodChannel. Native runs inference, writes WAV. Dart caches + plays.

---

## Three Big Decisions (Decide Before Day 1)

### 1. **Process Model**
```
Option A (Recommended): All engines in main process
  Pros: Simpler, faster IPC
  Cons: Potential native lib conflicts
  
Option B (If conflicts): Separate process per engine (:kokoro, :piper, :supertonic)
  Pros: Complete isolation
  Cons: Complex Binder IPC, harder debug
  
HOW TO DECIDE: Run Model Coexistence Test (1 hour) → tells you immediately
```

### 2. **Audio Format**
```
Sample rate: 24000 Hz (sweet spot)
Channels: Mono (16-bit PCM)
Resample: Let just_audio handle (it's optimized)
Cache key: Include sample rate (prevent mistakes)
```

### 3. **First Engine Target**
```
Kokoro ← START HERE (simplest, fewer deps)
  Then: Piper (requires phonemizer, more complex)
  Then: Supertonic (needs speaker embeddings)
```

---

## The Three Risk Tests (Do These First - 2-3 Hours)

Run before Phase 1:

### Test 1: Model Coexistence (30 min)
**Question:** Can we load Kokoro + Piper models together without crashes?
```kotlin
Load Kokoro → synthesize → verify output
Load Piper → synthesize → verify output
Check memory delta
```
**If OK:** Use Option A (single process, simpler)
**If crashes/OOM:** Use Option B (multi-process, complex)

### Test 2: Audio Format Validation (30 min)
**Question:** Does native code produce valid, playable WAV?
```dart
Synthesize segment → parse WAV header (16-bit, mono, 24kHz)
Play via just_audio → listen for 2 seconds
Measure duration (must be >500ms)
```
**If OK:** Proceed to Phase 1
**If fails:** Debug native WAV writer

### Test 3: Cancellation Safety (30 min)
**Question:** If user skips mid-synthesis, do we leave partial files?
```dart
Start 5 synths concurrently
Cancel after 50ms
Verify no .tmp files remain on disk
```
**If OK:** Cancellation protocol is safe
**If fails:** Add .tmp cleanup before Phase 5

---

## Phase-by-Phase Timeline (4-5 Weeks)

| Phase | Duration | Key Deliverable |
|-------|----------|-----------------|
| **1** | Days 1-2 | Risk tests pass + decisions locked |
| **2** | Days 3-4 | TtsEngine interfaces + adapters defined |
| **3** | Days 5-7 | Native layer scaffold (Pigeon contract) |
| **4** | Days 8-9 | Kokoro native service (synthesize to WAV) |
| **5** | Days 10-12 | Asset pipeline (download, verify, extract) |
| **6** | Days 13-14 | Model caching + memory management |
| **7** | Days 15-17 | Piper integration (+ phonemizer) |
| **8** | Days 18-20 | Supertonic integration (+ embeddings) |
| **9** | Days 21-23 | Playback + buffer scheduler integration |
| **10** | Days 24-27 | Performance hardening + tests |

---

## What Gets Delivered Per Phase

### Phase 1 ✅
- Risk tests passing
- Architecture decided (Option A or B)
- Decision matrix filled in

### Phase 4 ✅
- Kokoro synthesizes "hello world" → WAV on disk
- WAV plays via just_audio

### Phase 5 ✅
- EPUB import → chapters extracted
- Downloaded cores verified via SHA256
- Atomic .tmp pattern in place

### Phase 7 ✅
- User selects 2 engines
- Both voices available + switchable mid-playback

### Phase 10 ✅
- All 3 engines working
- Cold synth <5s, warm cache <500ms
- Stress test (50 requests) passes
- Crash rate <0.1%

---

## Key Files to Create (Per Phase)

### Phase 2 (Interfaces)
```
packages/tts_engines/lib/
├── interfaces/tts_engine.dart (updated with state machines)
├── adapters/
│   ├── kokoro_adapter.dart (no native yet)
│   ├── piper_adapter.dart (stub)
│   └── supertonic_adapter.dart (stub)
└── synthesis_pool.dart (updated with cancellation)
```

### Phase 3 (Platform Contract)
```
packages/platform_android/
├── pigeons/tts_service.dart (Pigeon definition)
└── android/src/main/kotlin/com/audiobook/tts/
    ├── GeneratedTtsApi.kt (auto-generated by Pigeon)
    ├── KokoroTtsService.kt (native inference)
    └── TtsNativeApi.kt (interface)
```

### Phase 5 (Assets)
```
packages/downloads/
├── lib/manifests/
│   ├── voices_manifest.json (voice specs + download URLs)
│   └── core_specs.json (core version tracking)
└── lib/impl/voice_asset_manager.dart (atomic download + verify)
```

---

## State Machines (Used in Phases 2, 9)

### Core Ready State Flow
```
notStarted
  ↓ (user picks voice)
downloading (showing progress bar)
  ↓ (download done)
extracting (showing "extracting...")
  ↓ (extraction done)
verifying (SHA256 check)
  ↓ (hash matches)
loaded (model in memory)
  ↓ (first synth request)
ready (ready to synthesize)

OR at any step:
[state] → failed (error) ← user taps "Retry" → downloading (again)
```

**UI advantage:** Show exact state to user ("Downloading 250MB: 45%")

### Synth Lifecycle
```
queued → inferencing → writingFile → cacheMoving → complete
                ↑                                    ↓
                └────────────────────────────────────┘
                      (on cancel: delete .tmp)
```

---

## Critical Safety Patterns

### Pattern 1: Atomic Download
```
1. Download to .tar.gz.tmp (resumable)
2. Extract to dir.tmp (not final location)
3. Verify SHA256 on dir.tmp
4. Rename: dir.tmp → dir (atomic)
5. Cleanup .old directory
Result: Never partial or corrupted core on disk
```

### Pattern 2: Cancellation = .tmp Cleanup
```
User clicks skip
  ↓
Dart calls cancel(opId)
  ↓
Native sets cancel flag + deletes /path/to/file.tmp
  ↓
No partial WAV files left behind
```

### Pattern 3: Memory Pressure
```
Device has 4GB RAM?
  → Keep 1 model loaded max
  → Unload on memory pressure
  
Device has 12GB RAM?
  → Keep 3 models loaded
  → Lazy unload (only if <500MB free)
```

---

## How to Use This Strategy

### Day 1 Morning
```
1. Read "Executive Summary" (this file) - 15 min
2. Read "Decision Matrix" section (full strategy) - 30 min
3. Make 3 architectural decisions - 30 min
4. Commit decisions to repo - 10 min
```

### Day 1 Afternoon
```
5. Run Model Coexistence Test - 30 min
   (reads pass/fail, decide Option A vs B)
6. Run Audio Format Test - 30 min
7. Run Cancellation Safety Test - 30 min
```

### Day 2
```
8. If all tests pass: Start Phase 2
   If test fails: Debug + iterate, then Phase 2
```

---

## Questions Your AI Agent Might Ask

### Q: "Do I need to implement iOS right away?"
**A:** No. Implement Android first (Phases 1-10 = 4 weeks). iOS later (1 week) using FlutterTts fallback.

### Q: "Should I pre-download models or let app fetch on first run?"
**A:** Fetch on first run (Phase 5 asset pipeline handles this). Show progress bar.

### Q: "What if model file is corrupted?"
**A:** SHA256 mismatch during verify → delete + re-download. Atomic pattern prevents partial state.

### Q: "How do I test without models?"
**A:** Use tiny test fixtures (1KB dummy ONNX file) in Phase 1. Real models loaded in Phase 7+.

### Q: "What happens if user force-quits during download?"
**A:** Download state saved. Next run resumes from .tmp file. No corruption.

### Q: "How do I handle 'native library not found' errors?"
**A:** Wrap all native calls in try/catch. Map to EngineError enum. UI shows user action needed.

---

## Success Criteria (Phase 10 Exit)

- [ ] Kokoro synthesizes "hello world" → WAV plays (Days 1-4)
- [ ] Piper synthesizes with phonemizer (Days 15-17)
- [ ] Supertonic uses speaker embeddings (Days 18-20)
- [ ] Cache hit rate >90% on repeat plays
- [ ] Cold synth <5s, warm <500ms
- [ ] Memory peak <300MB
- [ ] 50 rapid synth requests succeed (stress test)
- [ ] Cancellation leaves no partial files
- [ ] UI shows exact progress ("Downloading 45%", "Inferencing...", etc)

---

## Next Steps

1. **Share this doc with your AI agent**
2. **Share the full strategy** (TTS_implementation_improved.md)
3. **Share your decision matrix** (fill in Section 0)
4. **Agent starts Phase 1** immediately

---

**Status:** Ready to implement. No blockers. 4-5 weeks to production TTS.
